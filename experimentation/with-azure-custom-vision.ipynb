{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f72b785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-cognitiveservices-vision-customvision in c:\\users\\olalere\\anaconda3\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: kagglehub in c:\\users\\olalere\\anaconda3\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\olalere\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: msrest>=0.6.21 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-vision-customvision) (0.7.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-vision-customvision) (1.1.28)\n",
      "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.2.0 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-vision-customvision) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from kagglehub) (24.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from kagglehub) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from kagglehub) (4.66.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from matplotlib) (2.0.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: azure-core>=1.32.0 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-vision-customvision) (1.36.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (2025.6.15)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (0.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from azure-core>=1.32.0->azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-vision-customvision) (4.11.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\olalere\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (3.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-cognitiveservices-vision-customvision kagglehub matplotlib\n",
    "import os, time, uuid\n",
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9695b665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded to: C:\\Users\\OLALERE\\.cache\\kagglehub\\datasets\\elinteerie\\nigeria-food-ai-dataset\\versions\\3\n",
      "Contents: ['1HZhs21IE2oNn_V7PF_atNDizdhV8z-vP', '1HZhs21IE2oNn_V7PF_atNDizdhV8z-vP.zip', 'unzipped_dataset']\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Download dataset\n",
    "path = kagglehub.dataset_download(\"elinteerie/nigeria-food-ai-dataset\")\n",
    "print(\"Downloaded to:\", path)\n",
    "print(\"Contents:\", os.listdir(path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f08f682",
   "metadata": {},
   "source": [
    "The dataset was in a binary format,it has to be extracted to view the content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6903efbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipped dataset to: C:\\Users\\OLALERE\\.cache\\kagglehub\\datasets\\elinteerie\\nigeria-food-ai-dataset\\versions\\3\\unzipped_dataset\n",
      "Extracted contents: ['nigfoodai']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# path from kagglehub\n",
    "dataset_file = os.path.join(path, \"1HZhs21IE2oNn_V7PF_atNDizdhV8z-vP\")\n",
    "\n",
    "# Give it a temporary .zip extension if it doesn't have one\n",
    "alt_file = dataset_file + \".zip\"\n",
    "shutil.copy(dataset_file, alt_file)\n",
    "\n",
    "# Extract to a folder\n",
    "extract_dir = os.path.join(path, \"unzipped_dataset\")\n",
    "\n",
    "if zipfile.is_zipfile(alt_file):\n",
    "    with zipfile.ZipFile(alt_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "        print(\"Unzipped dataset to:\", extract_dir)\n",
    "else:\n",
    "    print(\"File was not a zip archive — might be nested differently.\")\n",
    "\n",
    "# Check what we got\n",
    "print(\"Extracted contents:\", os.listdir(extract_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34113ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting inner contents:\n",
      "['akarabread', 'banga', 'bitterleaf', 'edikakong', 'egusi', 'ewedu', 'garriandgrounut', 'jellof', 'moimoi', 'nkwobi', 'ofeowerri', 'ogbono', 'okra', 'pufpuf']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inner_path = os.path.join(path, \"unzipped_dataset\", \"nigfoodai\")\n",
    "print(\"Inspecting inner contents:\")\n",
    "print(os.listdir(inner_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d10a859b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akarabread: 190 images\n",
      "banga: 49 images\n",
      "bitterleaf: 49 images\n",
      "edikakong: 107 images\n",
      "egusi: 550 images\n",
      "ewedu: 247 images\n",
      "garriandgrounut: 97 images\n",
      "jellof: 455 images\n",
      "moimoi: 228 images\n",
      "nkwobi: 52 images\n",
      "ofeowerri: 58 images\n",
      "ogbono: 621 images\n",
      "okra: 549 images\n",
      "pufpuf: 197 images\n"
     ]
    }
   ],
   "source": [
    "base_images_dir = inner_path\n",
    "for folder in os.listdir(base_images_dir):\n",
    "    folder_path = os.path.join(base_images_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        imgs = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        print(f\"{folder}: {len(imgs)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a05b1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = os.environ[\"VISION_TRAINING_ENDPOINT\"]\n",
    "training_key = os.environ[\"VISION_TRAINING_KEY\"]\n",
    "prediction_key = os.environ[\"VISION_PREDICTION_KEY\"]\n",
    "prediction_resource_id = os.environ[\"VISION_PREDICTION_RESOURCE_ID\"]\n",
    "\n",
    "# Authenticate\n",
    "training_credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "\n",
    "trainer = CustomVisionTrainingClient(ENDPOINT, training_credentials)\n",
    "predictor = CustomVisionPredictionClient(ENDPOINT, prediction_credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86575326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating project...\n",
      "Project created: FoodImageClassifier-bb0f7e9d-c4ba-44cd-a9fb-74d35e963c1f\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating project...\")\n",
    "project_name = f\"FoodImageClassifier-{uuid.uuid4()}\"\n",
    "project = trainer.create_project(project_name)\n",
    "print(\"Project created:\", project.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "506f3dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading for label: akarabread\n",
      "  Batch 1/3: uploaded 64\n",
      "  Batch 2/3: failed — retry later.\n",
      "  Batch 3/3: failed — retry later.\n",
      "Completed: akarabread\n",
      "\n",
      "Uploading for label: banga\n",
      "  Batch 1/1: uploaded 49\n",
      "Completed: banga\n",
      "\n",
      "Uploading for label: bitterleaf\n",
      "  Batch 1/1: uploaded 49\n",
      "Completed: bitterleaf\n",
      "\n",
      "Uploading for label: edikakong\n",
      "  Batch 1/2: uploaded 64\n",
      "  Batch 2/2: failed — retry later.\n",
      "Completed: edikakong\n",
      "\n",
      "Uploading for label: egusi\n",
      "  Batch 1/9: uploaded 64\n",
      "  Batch 2/9: failed — retry later.\n",
      "  Batch 3/9: failed — retry later.\n",
      "  Batch 4/9: failed — retry later.\n",
      "  Batch 5/9: failed — retry later.\n",
      "  Batch 6/9: failed — retry later.\n",
      "  Batch 7/9: failed — retry later.\n",
      "  Batch 8/9: failed — retry later.\n",
      "  Batch 9/9: uploaded 38\n",
      "Completed: egusi\n",
      "\n",
      "Uploading for label: ewedu\n",
      "  Batch 1/4: failed — retry later.\n",
      "  Batch 2/4: failed — retry later.\n",
      "  Batch 3/4: failed — retry later.\n",
      "  Batch 4/4: failed — retry later.\n",
      "Completed: ewedu\n",
      "\n",
      "Uploading for label: garriandgrounut\n",
      "  Batch 1/2: failed — retry later.\n",
      "  Batch 2/2: failed — retry later.\n",
      "Completed: garriandgrounut\n",
      "\n",
      "Uploading for label: jellof\n",
      "  Batch 1/8: uploaded 64\n",
      "  Batch 2/8: failed — retry later.\n",
      "  Batch 3/8: failed — retry later.\n",
      "  Batch 4/8: failed — retry later.\n",
      "  Batch 5/8: failed — retry later.\n",
      "  Batch 6/8: failed — retry later.\n",
      "  Batch 7/8: failed — retry later.\n",
      "  Batch 8/8: failed — retry later.\n",
      "Completed: jellof\n",
      "\n",
      "Uploading for label: moimoi\n",
      "  Batch 1/4: uploaded 64\n",
      "  Batch 2/4: uploaded 64\n",
      "  Batch 3/4: failed — retry later.\n",
      "  Batch 4/4: failed — retry later.\n",
      "Completed: moimoi\n",
      "\n",
      "Uploading for label: nkwobi\n",
      "  Batch 1/1: failed — retry later.\n",
      "Completed: nkwobi\n",
      "\n",
      "Uploading for label: ofeowerri\n",
      "  Batch 1/1: failed — retry later.\n",
      "Completed: ofeowerri\n",
      "\n",
      "Uploading for label: ogbono\n",
      "  Batch 1/10: uploaded 64\n",
      "  Batch 2/10: failed — retry later.\n",
      "  Batch 3/10: failed — retry later.\n",
      "  Batch 4/10: failed — retry later.\n",
      "  Batch 5/10: failed — retry later.\n",
      "  Batch 6/10: failed — retry later.\n",
      "  Batch 7/10: failed — retry later.\n",
      "  Batch 8/10: failed — retry later.\n",
      "  Batch 9/10: failed — retry later.\n",
      "  Batch 10/10: failed — retry later.\n",
      "Completed: ogbono\n",
      "\n",
      "Uploading for label: okra\n",
      "  Batch 1/9: failed — retry later.\n",
      "  Batch 2/9: failed — retry later.\n",
      "  Batch 3/9: failed — retry later.\n",
      "  Batch 4/9: failed — retry later.\n",
      "  Batch 5/9: failed — retry later.\n",
      "  Batch 6/9: failed — retry later.\n",
      "  Batch 7/9: failed — retry later.\n",
      "  Batch 8/9: failed — retry later.\n",
      "  Batch 9/9: failed — retry later.\n",
      "Completed: okra\n",
      "\n",
      "Uploading for label: pufpuf\n",
      "  Batch 1/4: failed — retry later.\n",
      "  Batch 2/4: failed — retry later.\n",
      "  Batch 3/4: failed — retry later.\n",
      "  Batch 4/4: uploaded 5\n",
      "Completed: pufpuf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, math, json, time\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "PROGRESS_FILE = \"upload_progress.json\"\n",
    "\n",
    "# load checkpoint if any\n",
    "if os.path.exists(PROGRESS_FILE):\n",
    "    with open(PROGRESS_FILE, \"r\") as f:\n",
    "        uploaded = json.load(f)\n",
    "else:\n",
    "    uploaded = {}\n",
    "\n",
    "def mark_uploaded(label, filenames):\n",
    "    uploaded.setdefault(label, [])\n",
    "    uploaded[label].extend(filenames)\n",
    "    with open(PROGRESS_FILE, \"w\") as f:\n",
    "        json.dump(uploaded, f)\n",
    "\n",
    "for label in os.listdir(base_images_dir):\n",
    "    folder = os.path.join(base_images_dir, label)\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "\n",
    "    # skip labels already finished\n",
    "    if label in uploaded and uploaded[label] == \"DONE\":\n",
    "        print(f\"{label}: already completed.\")\n",
    "        continue\n",
    "\n",
    "    # find or create tag\n",
    "    existing_tags = {t.name: t for t in trainer.get_tags(project.id)}\n",
    "    tag = existing_tags.get(label) or trainer.create_tag(project.id, label)\n",
    "    print(f\"Uploading for label: {label}\")\n",
    "\n",
    "    images = [f for f in os.listdir(folder) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
    "    already = set(uploaded.get(label, []))\n",
    "    remaining = [img for img in images if img not in already]\n",
    "    total_batches = math.ceil(len(remaining) / BATCH_SIZE)\n",
    "\n",
    "    for i in range(total_batches):\n",
    "        batch_files = remaining[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "        entries = []\n",
    "        for img_file in batch_files:\n",
    "            try:\n",
    "                img_path = os.path.join(folder, img_file)\n",
    "                with open(img_path, \"rb\") as f:\n",
    "                    entries.append(ImageFileCreateEntry(name=img_file, contents=f.read(), tag_ids=[tag.id]))\n",
    "            except Exception as e:\n",
    "                print(f\"Skipped {img_file}: {e}\")\n",
    "\n",
    "        if not entries:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            result = trainer.create_images_from_files(project.id, ImageFileCreateBatch(images=entries))\n",
    "            if result.is_batch_successful:\n",
    "                mark_uploaded(label, batch_files)\n",
    "                print(f\"  Batch {i+1}/{total_batches}: uploaded {len(batch_files)}\")\n",
    "            else:\n",
    "                print(f\"  Batch {i+1}/{total_batches}: failed — retry later.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Batch {i+1}/{total_batches} failed: {e}\")\n",
    "            break  # break to avoid hammering Azure API\n",
    "\n",
    "    # mark label done\n",
    "    uploaded[label] = \"DONE\"\n",
    "    with open(PROGRESS_FILE, \"w\") as f:\n",
    "        json.dump(uploaded, f)\n",
    "\n",
    "    print(f\"Completed: {label}\\n\")\n",
    "    time.sleep(1)  # small pause to stay under rate limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "706d46d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okra: 524 images\n",
      "ogbono: 595 images\n",
      "moimoi: 219 images\n",
      "garriandgrounut: 94 images\n",
      "edikakong: 107 images\n",
      "akarabread: 186 images\n",
      "pufpuf: 187 images\n",
      "ewedu: 228 images\n",
      "ofeowerri: 56 images\n",
      "bitterleaf: 49 images\n",
      "nkwobi: 50 images\n",
      "jellof: 428 images\n",
      "egusi: 531 images\n",
      "banga: 49 images\n"
     ]
    }
   ],
   "source": [
    "tags = trainer.get_tags(project.id)\n",
    "for tag in tags:\n",
    "    print(f\"{tag.name}: {tag.image_count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d87377e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Completed\n",
      "Training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "iteration = trainer.train_project(project.id)\n",
    "\n",
    "while iteration.status != \"Completed\":\n",
    "    time.sleep(10)\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print(\"Training status:\", iteration.status)\n",
    "\n",
    "print(\"Training completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8b4f7b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "CustomVisionErrorException",
     "evalue": "Iteration is already published as: FoodClassifierModel",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCustomVisionErrorException\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m publish_iteration_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFoodClassifierModel\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m trainer\u001b[38;5;241m.\u001b[39mpublish_iteration(\n\u001b[0;32m      4\u001b[0m     project\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m      5\u001b[0m     iteration\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m      6\u001b[0m     publish_iteration_name,\n\u001b[0;32m      7\u001b[0m     prediction_resource_id\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPublished iteration:\u001b[39m\u001b[38;5;124m\"\u001b[39m, publish_iteration_name)\n",
      "File \u001b[1;32mc:\\Users\\OLALERE\\anaconda3\\Lib\\site-packages\\azure\\cognitiveservices\\vision\\customvision\\training\\operations\\_custom_vision_training_client_operations.py:2522\u001b[0m, in \u001b[0;36mCustomVisionTrainingClientOperationsMixin.publish_iteration\u001b[1;34m(self, project_id, iteration_id, publish_name, prediction_id, overwrite, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[0;32m   2519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(request, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moperation_config)\n\u001b[0;32m   2521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m200\u001b[39m]:\n\u001b[1;32m-> 2522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m models\u001b[38;5;241m.\u001b[39mCustomVisionErrorException(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize, response)\n\u001b[0;32m   2524\u001b[0m deserialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "\u001b[1;31mCustomVisionErrorException\u001b[0m: Iteration is already published as: FoodClassifierModel"
     ]
    }
   ],
   "source": [
    "publish_iteration_name = \"FoodClassifierModel\"\n",
    "\n",
    "trainer.publish_iteration(\n",
    "    project.id,\n",
    "    iteration.id,\n",
    "    publish_iteration_name,\n",
    "    prediction_resource_id\n",
    ")\n",
    "\n",
    "print(\"Published iteration:\", publish_iteration_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c8d809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ofeowerri: 67.07%\n",
      "ogbono: 49.80%\n",
      "bitterleaf: 22.95%\n",
      "banga: 4.91%\n",
      "egusi: 4.46%\n",
      "nkwobi: 0.84%\n",
      "okra: 0.47%\n",
      "edikakong: 0.30%\n",
      "jellof: 0.20%\n",
      "moimoi: 0.16%\n",
      "ewedu: 0.15%\n",
      "akarabread: 0.05%\n",
      "garriandgrounut: 0.03%\n",
      "pufpuf: 0.01%\n"
     ]
    }
   ],
   "source": [
    "# Testing with a sample image\n",
    "sample_image_path = r\"C:\\Users\\OLALERE\\Downloads\\Testimages\\IMG-20251027-WA0008.jpg\"\n",
    "\n",
    "with open(sample_image_path, \"rb\") as image_data:\n",
    "    results = predictor.classify_image(\n",
    "        project.id,\n",
    "        publish_iteration_name,\n",
    "        image_data.read()\n",
    "    )\n",
    "\n",
    "for prediction in results.predictions:\n",
    "    print(f\"{prediction.tag_name}: {prediction.probability * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8198a4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IMG-20251027-WA0004.jpg\n",
      "  moimoi: 98.34%\n",
      "  ewedu: 31.11%\n",
      "  akarabread: 5.79%\n",
      "\n",
      "IMG-20251027-WA0005.jpg\n",
      "  moimoi: 90.42%\n",
      "  nkwobi: 35.60%\n",
      "  egusi: 5.30%\n",
      "\n",
      "IMG-20251027-WA0006.jpg\n",
      "  ogbono: 76.98%\n",
      "  banga: 12.87%\n",
      "  nkwobi: 5.56%\n",
      "\n",
      "IMG-20251027-WA0007.jpg\n",
      "  pufpuf: 98.91%\n",
      "  ogbono: 2.89%\n",
      "  bitterleaf: 2.25%\n",
      "\n",
      "IMG-20251027-WA0008.jpg\n",
      "  ofeowerri: 67.07%\n",
      "  ogbono: 49.80%\n",
      "  bitterleaf: 22.95%\n",
      "\n",
      "IMG-20251027-WA0009.jpg\n",
      "  pufpuf: 99.40%\n",
      "  ogbono: 3.05%\n",
      "  akarabread: 1.88%\n",
      "\n",
      "IMG-20251027-WA0010.jpg\n",
      "  ogbono: 28.39%\n",
      "  banga: 27.29%\n",
      "  egusi: 7.29%\n",
      "\n",
      "IMG-20251027-WA0011.jpg\n",
      "  ewedu: 96.21%\n",
      "  edikakong: 9.88%\n",
      "  egusi: 4.36%\n",
      "\n",
      "IMG-20251027-WA0012.jpg\n",
      "  jellof: 99.69%\n",
      "  egusi: 7.36%\n",
      "  banga: 2.22%\n",
      "\n",
      "IMG-20251027-WA0013.jpg\n",
      "  nkwobi: 95.16%\n",
      "  okra: 5.30%\n",
      "  jellof: 3.07%\n",
      "\n",
      "IMG-20251027-WA0014.jpg\n",
      "  garriandgrounut: 98.68%\n",
      "  okra: 2.01%\n",
      "  akarabread: 1.78%\n",
      "\n",
      "IMG-20251027-WA0015.jpg\n",
      "  nkwobi: 92.42%\n",
      "  banga: 13.16%\n",
      "  ogbono: 4.98%\n",
      "\n",
      "IMG-20251027-WA0016.jpg\n",
      "  nkwobi: 99.30%\n",
      "  moimoi: 3.36%\n",
      "  jellof: 3.20%\n",
      "\n",
      "IMG-20251027-WA0017.jpg\n",
      "  ogbono: 67.51%\n",
      "  ofeowerri: 19.10%\n",
      "  banga: 17.60%\n",
      "\n",
      "IMG-20251027-WA0018.jpg\n",
      "  banga: 29.20%\n",
      "  egusi: 24.55%\n",
      "  ogbono: 11.97%\n",
      "\n",
      "IMG-20251027-WA0019.jpg\n",
      "  edikakong: 32.08%\n",
      "  bitterleaf: 8.18%\n",
      "  egusi: 5.42%\n",
      "\n",
      "IMG-20251027-WA0020.jpg\n",
      "  garriandgrounut: 99.31%\n",
      "  okra: 8.36%\n",
      "  akarabread: 4.60%\n",
      "\n",
      "IMG-20251027-WA0021.jpg\n",
      "  ewedu: 96.27%\n",
      "  garriandgrounut: 4.77%\n",
      "  bitterleaf: 1.96%\n",
      "\n",
      "IMG-20251027-WA0022.jpg\n",
      "  jellof: 99.08%\n",
      "  egusi: 2.44%\n",
      "  garriandgrounut: 0.93%\n",
      "\n",
      "IMG-20251027-WA0023.jpg\n",
      "  edikakong: 38.51%\n",
      "  egusi: 9.09%\n",
      "  ewedu: 8.00%\n",
      "\n",
      "WhatsApp Image 2025-10-27 at 17.46.44_c2cacd5f.jpg\n",
      "  ogbono: 28.39%\n",
      "  banga: 27.29%\n",
      "  egusi: 7.29%\n"
     ]
    }
   ],
   "source": [
    "#Testing with multiple images\n",
    "test_path = r\"C:\\Users\\OLALERE\\Downloads\\Testimages\"\n",
    "\n",
    "# If directory, pick one or loop through all\n",
    "if os.path.isdir(test_path):\n",
    "    files = [f for f in os.listdir(test_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No image files found in directory: {test_path}\")\n",
    "else:\n",
    "    files = [os.path.basename(test_path)]\n",
    "    test_path = os.path.dirname(test_path)\n",
    "\n",
    "# Loop through each image file\n",
    "for filename in files:\n",
    "    img_path = os.path.join(test_path, filename)\n",
    "    with open(img_path, \"rb\") as image_data:\n",
    "        image_bytes = image_data.read()\n",
    "        results = predictor.classify_image(\n",
    "            project.id,\n",
    "            publish_iteration_name,\n",
    "            image_bytes\n",
    "        )\n",
    "\n",
    "    print(f\"\\n{filename}\")\n",
    "    for prediction in results.predictions[:3]:\n",
    "        print(f\"  {prediction.tag_name}: {prediction.probability * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc065fb2",
   "metadata": {},
   "source": [
    "## **Documentations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f08f960",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "```markdown\n",
    "# Azure Custom Vision Food Image Classifier  \n",
    "**Contributor:** *Robiu Olalere / Algebra101*  \n",
    "\n",
    "---\n",
    "\n",
    "## Overview  \n",
    "This notebook demonstrates how to build a **food image classifier** using **Azure Custom Vision** and a **Kaggle dataset of Nigerian foods**.  \n",
    "The objective was to automate dataset upload, train a multiclass classifier, and expose prediction endpoints for local inference.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset  \n",
    "- **Source:** [Nigeria Food AI Dataset (Kaggle)](https://www.kaggle.com/datasets/elinteerie/nigeria-food-ai-dataset)  \n",
    "- The dataset is stored in a **binary format**, so it must be **extracted** before Azure Custom Vision recognizes the images.  \n",
    "- There is noticeable **class imbalance**, which slightly reduced recall for underrepresented classes.  \n",
    "- Example: foods with fewer samples showed recall below 50%, while classes with more samples achieved higher precision and recall.\n",
    "\n",
    "---\n",
    "\n",
    "## Data Upload  \n",
    "A custom uploader script was implemented to handle robust dataset uploading:\n",
    "\n",
    "- Handles extraction from KaggleHub cache.  \n",
    "- Uploads images in **batches of 64** (Azure’s upload limit).  \n",
    "- Supports **automatic resume** after network interruptions using a local progress checkpoint file.  \n",
    "- Total upload time: **≈ 29 minutes 30 seconds**.  \n",
    "\n",
    "---\n",
    "\n",
    "## Model Training  \n",
    "- **Project type:** Classification (Multiclass)  \n",
    "- **Training duration:** 12 minutes 32 seconds  \n",
    "\n",
    "**Performance (Threshold = 50%)**\n",
    "| Metric | Score |\n",
    "|:--|:--|\n",
    "| Precision | 92.2% |\n",
    "| Recall | 74.7% |\n",
    "| Average Precision (AP) | 91.2% |\n",
    "\n",
    "**Observations**\n",
    "- High-sample classes → stronger precision and recall.  \n",
    "- Some smaller classes still performed well despite low image counts.\n",
    "\n",
    "---\n",
    "\n",
    "## API Keys and Environment  \n",
    "During experimentation, it was observed that:\n",
    "- If the initial API key fails or expires, a **manual override** in the code may be required even after updating the `.env` file.  \n",
    "- The guide includes steps for resetting and re-authenticating both **Training** and **Prediction** clients programmatically.  \n",
    "\n",
    "---\n",
    "\n",
    "## Prediction Endpoints  \n",
    "**Image URL Endpoint:**  \n",
    "```\n",
    "\n",
    "[https://myclassifier-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/cbb3b58c-7d5e-4436-9ab3-5af77ee3f197/classify/iterations/FoodClassifierModel/url]\n",
    "```\n",
    "\n",
    "**Image File Endpoint:**  \n",
    "```\n",
    "\n",
    "[https://myclassifier-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/cbb3b58c-7d5e-4436-9ab3-5af77ee3f197/classify/iterations/FoodClassifierModel/image]\n",
    "\n",
    "````\n",
    "\n",
    "---\n",
    "\n",
    "## Example Inference (Python)\n",
    "```python\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "\n",
    "# Replace with your own values\n",
    "PREDICTION_KEY = \"<your_prediction_key>\"\n",
    "ENDPOINT = \"<your_endpoint>\"\n",
    "PROJECT_ID = \"<your_project_id>\"\n",
    "ITERATION_NAME = \"FoodClassifierModel\"\n",
    "\n",
    "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": PREDICTION_KEY})\n",
    "predictor = CustomVisionPredictionClient(ENDPOINT, credentials)\n",
    "\n",
    "with open(\"test_image.jpg\", \"rb\") as image_data:\n",
    "    results = predictor.classify_image(PROJECT_ID, ITERATION_NAME, image_data.read())\n",
    "\n",
    "for prediction in results.predictions:\n",
    "    print(f\"{prediction.tag_name}: {prediction.probability * 100:.2f}%\")\n",
    "````\n",
    "\n",
    "---\n",
    "\n",
    "## Notes and Recommendations\n",
    "\n",
    "* The class imbalance could be addressed by **oversampling** or **data augmentation** for smaller categories.\n",
    "* Future contributors can experiment with:\n",
    "\n",
    "  * **Advanced Training** mode in Azure Custom Vision\n",
    "  * **AutoML** for additional optimization\n",
    "* The notebook and documentation serve as a reproducible baseline for food image classification tasks in Azure Custom Vision.\n",
    "\n",
    "---\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2570b0d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
