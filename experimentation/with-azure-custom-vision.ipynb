{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f72b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install azure-cognitiveservices-vision-customvision kagglehub matplotlib\n",
    "import os, time, uuid\n",
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from msrest.authentication import ApiKeyCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9695b665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/Downloads/naija-nutri-hub/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/elinteerie/nigeria-food-ai-dataset?dataset_version_number=3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 843M/843M [05:02<00:00, 2.92MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded to: /Users/mac/.cache/kagglehub/datasets/elinteerie/nigeria-food-ai-dataset/versions/3\n",
      "Contents: ['1HZhs21IE2oNn_V7PF_atNDizdhV8z-vP']\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Download dataset\n",
    "path = kagglehub.dataset_download(\"elinteerie/nigeria-food-ai-dataset\")\n",
    "print(\"Downloaded to:\", path)\n",
    "print(\"Contents:\", os.listdir(path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f08f682",
   "metadata": {},
   "source": [
    "The dataset was in a binary format,it has to be extracted to view the content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6903efbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipped dataset to: /Users/mac/.cache/kagglehub/datasets/elinteerie/nigeria-food-ai-dataset/versions/3/unzipped_dataset\n",
      "Extracted contents: ['nigfoodai']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# path from kagglehub\n",
    "dataset_file = os.path.join(path, \"1HZhs21IE2oNn_V7PF_atNDizdhV8z-vP\")\n",
    "\n",
    "# Give it a temporary .zip extension if it doesn't have one\n",
    "alt_file = dataset_file + \".zip\"\n",
    "shutil.copy(dataset_file, alt_file)\n",
    "\n",
    "# Extract to a folder\n",
    "extract_dir = os.path.join(path, \"unzipped_dataset\")\n",
    "\n",
    "if zipfile.is_zipfile(alt_file):\n",
    "    with zipfile.ZipFile(alt_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "        print(\"Unzipped dataset to:\", extract_dir)\n",
    "else:\n",
    "    print(\"File was not a zip archive — might be nested differently.\")\n",
    "\n",
    "# Check what we got\n",
    "print(\"Extracted contents:\", os.listdir(extract_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34113ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting inner contents:\n",
      "['jellof', 'bitterleaf', 'okra', 'edikakong', 'moimoi', 'egusi', 'ogbono', 'pufpuf', 'banga', 'nkwobi', 'akarabread', 'garriandgrounut', 'ofeowerri', 'ewedu']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inner_path = os.path.join(path, \"unzipped_dataset\", \"nigfoodai\")\n",
    "print(\"Inspecting inner contents:\")\n",
    "print(os.listdir(inner_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d10a859b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jellof: 455 images\n",
      "bitterleaf: 49 images\n",
      "okra: 549 images\n",
      "edikakong: 107 images\n",
      "moimoi: 228 images\n",
      "egusi: 550 images\n",
      "ogbono: 621 images\n",
      "pufpuf: 197 images\n",
      "banga: 49 images\n",
      "nkwobi: 52 images\n",
      "akarabread: 190 images\n",
      "garriandgrounut: 97 images\n",
      "ofeowerri: 58 images\n",
      "ewedu: 247 images\n"
     ]
    }
   ],
   "source": [
    "base_images_dir = inner_path\n",
    "for folder in os.listdir(base_images_dir):\n",
    "    folder_path = os.path.join(base_images_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        imgs = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        print(f\"{folder}: {len(imgs)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48ac6aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a05b1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = os.getenv(\"VISION_TRAINING_ENDPOINT\")\n",
    "training_key = os.getenv(\"VISION_TRAINING_KEY\")\n",
    "PRED_ENDPOINT = os.getenv(\"VISION_PREDICTION_ENDPOINT\")\n",
    "prediction_key = os.getenv(\"VISION_PREDICTION_KEY\")\n",
    "prediction_resource_id = os.getenv(\"VISION_PREDICTION_RESOURCE_ID\")\n",
    "\n",
    "# Authenticate\n",
    "training_credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "\n",
    "trainer = CustomVisionTrainingClient(ENDPOINT, training_credentials)\n",
    "predictor = CustomVisionPredictionClient(PRED_ENDPOINT, prediction_credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86575326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating project...\n",
      "Project created: FoodImageClassifier-091ba31a-1a64-4605-83d3-13b54cf77a6a\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating project...\")\n",
    "project_name = f\"FoodImageClassifier-{uuid.uuid4()}\"\n",
    "project = trainer.create_project(project_name)\n",
    "print(\"Project created:\", project.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "506f3dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading for label: jellof\n",
      "  Batch 1/8: uploaded 64\n",
      "  Batch 2/8: failed — retry later.\n",
      "  Batch 3/8: failed — retry later.\n",
      "  Batch 4/8: failed — retry later.\n",
      "  Batch 5/8: failed — retry later.\n",
      "  Batch 6/8: failed — retry later.\n",
      "  Batch 7/8: failed — retry later.\n",
      "  Batch 8/8: uploaded 7\n",
      "Completed: jellof\n",
      "\n",
      "Uploading for label: bitterleaf\n",
      "  Batch 1/1: uploaded 49\n",
      "Completed: bitterleaf\n",
      "\n",
      "Uploading for label: okra\n",
      "  Batch 1/9: uploaded 64\n",
      "  Batch 2/9: failed — retry later.\n",
      "  Batch 3/9: failed — retry later.\n",
      "  Batch 4/9: failed — retry later.\n",
      "  Batch 5/9: failed — retry later.\n",
      "  Batch 6/9: failed — retry later.\n",
      "  Batch 7/9: failed — retry later.\n",
      "  Batch 8/9: failed — retry later.\n",
      "  Batch 9/9: failed — retry later.\n",
      "Completed: okra\n",
      "\n",
      "Uploading for label: edikakong\n",
      "  Batch 1/2: uploaded 64\n",
      "  Batch 2/2: uploaded 43\n",
      "Completed: edikakong\n",
      "\n",
      "Uploading for label: moimoi\n",
      "  Batch 1/4: failed — retry later.\n",
      "  Batch 2/4: failed — retry later.\n",
      "  Batch 3/4: failed — retry later.\n",
      "  Batch 4/4: failed — retry later.\n",
      "Completed: moimoi\n",
      "\n",
      "Uploading for label: egusi\n",
      "  Batch 1/9: uploaded 64\n",
      "  Batch 2/9: uploaded 64\n",
      "  Batch 3/9: failed — retry later.\n",
      "  Batch 4/9: failed — retry later.\n",
      "  Batch 5/9: failed — retry later.\n",
      "  Batch 6/9: failed — retry later.\n",
      "  Batch 7/9: failed — retry later.\n",
      "  Batch 8/9: failed — retry later.\n",
      "  Batch 9/9: failed — retry later.\n",
      "Completed: egusi\n",
      "\n",
      "Uploading for label: ogbono\n",
      "  Batch 1/10: failed — retry later.\n",
      "  Batch 2/10: failed — retry later.\n",
      "  Batch 3/10: failed — retry later.\n",
      "  Batch 4/10: failed — retry later.\n",
      "  Batch 5/10: failed — retry later.\n",
      "  Batch 6/10: failed — retry later.\n",
      "  Batch 7/10: failed — retry later.\n",
      "  Batch 8/10: failed — retry later.\n",
      "  Batch 9/10: failed — retry later.\n",
      "  Batch 10/10: failed — retry later.\n",
      "Completed: ogbono\n",
      "\n",
      "Uploading for label: pufpuf\n",
      "  Batch 1/4: uploaded 64\n",
      "  Batch 2/4: failed — retry later.\n",
      "Batch 3/4 failed: Internal server error\n",
      "Completed: pufpuf\n",
      "\n",
      "Uploading for label: banga\n",
      "  Batch 1/1: failed — retry later.\n",
      "Completed: banga\n",
      "\n",
      "Uploading for label: nkwobi\n",
      "  Batch 1/1: failed — retry later.\n",
      "Completed: nkwobi\n",
      "\n",
      "Uploading for label: akarabread\n",
      "  Batch 1/3: failed — retry later.\n",
      "  Batch 2/3: failed — retry later.\n",
      "  Batch 3/3: failed — retry later.\n",
      "Completed: akarabread\n",
      "\n",
      "Uploading for label: garriandgrounut\n",
      "  Batch 1/2: failed — retry later.\n",
      "  Batch 2/2: failed — retry later.\n",
      "Completed: garriandgrounut\n",
      "\n",
      "Uploading for label: ofeowerri\n",
      "  Batch 1/1: failed — retry later.\n",
      "Completed: ofeowerri\n",
      "\n",
      "Uploading for label: ewedu\n",
      "  Batch 1/4: failed — retry later.\n",
      "  Batch 2/4: failed — retry later.\n",
      "Batch 3/4 failed: Operation returned an invalid status code 'Service Unavailable'\n",
      "Completed: ewedu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, math, json, time\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "PROGRESS_FILE = \"upload_progress.json\"\n",
    "\n",
    "# load checkpoint if any\n",
    "if os.path.exists(PROGRESS_FILE):\n",
    "    with open(PROGRESS_FILE, \"r\") as f:\n",
    "        uploaded = json.load(f)\n",
    "else:\n",
    "    uploaded = {}\n",
    "\n",
    "def mark_uploaded(label, filenames):\n",
    "    uploaded.setdefault(label, [])\n",
    "    uploaded[label].extend(filenames)\n",
    "    with open(PROGRESS_FILE, \"w\") as f:\n",
    "        json.dump(uploaded, f)\n",
    "\n",
    "for label in os.listdir(base_images_dir):\n",
    "    folder = os.path.join(base_images_dir, label)\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "\n",
    "    # skip labels already finished\n",
    "    if label in uploaded and uploaded[label] == \"DONE\":\n",
    "        print(f\"{label}: already completed.\")\n",
    "        continue\n",
    "\n",
    "    # find or create tag\n",
    "    existing_tags = {t.name: t for t in trainer.get_tags(project.id)}\n",
    "    tag = existing_tags.get(label) or trainer.create_tag(project.id, label)\n",
    "    print(f\"Uploading for label: {label}\")\n",
    "\n",
    "    images = [f for f in os.listdir(folder) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
    "    already = set(uploaded.get(label, []))\n",
    "    remaining = [img for img in images if img not in already]\n",
    "    total_batches = math.ceil(len(remaining) / BATCH_SIZE)\n",
    "\n",
    "    for i in range(total_batches):\n",
    "        batch_files = remaining[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "        entries = []\n",
    "        for img_file in batch_files:\n",
    "            try:\n",
    "                img_path = os.path.join(folder, img_file)\n",
    "                with open(img_path, \"rb\") as f:\n",
    "                    entries.append(ImageFileCreateEntry(name=img_file, contents=f.read(), tag_ids=[tag.id]))\n",
    "            except Exception as e:\n",
    "                print(f\"Skipped {img_file}: {e}\")\n",
    "\n",
    "        if not entries:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            result = trainer.create_images_from_files(project.id, ImageFileCreateBatch(images=entries))\n",
    "            if result.is_batch_successful:\n",
    "                mark_uploaded(label, batch_files)\n",
    "                print(f\"  Batch {i+1}/{total_batches}: uploaded {len(batch_files)}\")\n",
    "            else:\n",
    "                print(f\"  Batch {i+1}/{total_batches}: failed — retry later.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Batch {i+1}/{total_batches} failed: {e}\")\n",
    "            break  # break to avoid hammering Azure API\n",
    "\n",
    "    # mark label done\n",
    "    uploaded[label] = \"DONE\"\n",
    "    with open(PROGRESS_FILE, \"w\") as f:\n",
    "        json.dump(uploaded, f)\n",
    "\n",
    "    print(f\"Completed: {label}\\n\")\n",
    "    time.sleep(1)  # small pause to stay under rate limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "706d46d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "garriandgrounut: 94 images\n",
      "nkwobi: 50 images\n",
      "moimoi: 219 images\n",
      "jellof: 428 images\n",
      "ewedu: 140 images\n",
      "egusi: 531 images\n",
      "ofeowerri: 56 images\n",
      "akarabread: 186 images\n",
      "edikakong: 107 images\n",
      "pufpuf: 124 images\n",
      "okra: 524 images\n",
      "banga: 49 images\n",
      "bitterleaf: 49 images\n",
      "ogbono: 595 images\n"
     ]
    }
   ],
   "source": [
    "tags = trainer.get_tags(project.id)\n",
    "for tag in tags:\n",
    "    print(f\"{tag.name}: {tag.image_count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d87377e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Completed\n",
      "Training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "iteration = trainer.train_project(project.id)\n",
    "\n",
    "while iteration.status != \"Completed\":\n",
    "    time.sleep(10)\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print(\"Training status:\", iteration.status)\n",
    "\n",
    "print(\"Training completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8b4f7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published iteration: Naija-Food-Classifier-Model\n"
     ]
    }
   ],
   "source": [
    "publish_iteration_name = \"Naija-Food-Classifier-Model\"\n",
    "\n",
    "trainer.publish_iteration(\n",
    "    project.id,\n",
    "    iteration.id,\n",
    "    publish_iteration_name,\n",
    "    prediction_resource_id\n",
    ")\n",
    "\n",
    "print(\"Published iteration:\", publish_iteration_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03c8d809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akarabread: 98.43%\n",
      "garriandgrounut: 2.23%\n",
      "pufpuf: 2.07%\n",
      "moimoi: 1.64%\n",
      "egusi: 1.35%\n",
      "okra: 0.46%\n",
      "ogbono: 0.31%\n",
      "ewedu: 0.21%\n",
      "ofeowerri: 0.17%\n",
      "edikakong: 0.13%\n",
      "jellof: 0.10%\n",
      "nkwobi: 0.07%\n",
      "bitterleaf: 0.05%\n",
      "banga: 0.02%\n"
     ]
    }
   ],
   "source": [
    "# Testing with a sample image\n",
    "sample_image_path = \"../src/food_classifier/test_images/image.jpg\"\n",
    "\n",
    "with open(sample_image_path, \"rb\") as image_data:\n",
    "    results = predictor.classify_image(\n",
    "        project.id,\n",
    "        publish_iteration_name,\n",
    "        image_data.read()\n",
    "    )\n",
    "\n",
    "for prediction in results.predictions:\n",
    "    print(f\"{prediction.tag_name}: {prediction.probability * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8198a4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ogbono-soup-Draw-Soup-IG-1-500x500.jpg\n",
      "  ogbono: 89.59%\n",
      "  banga: 32.24%\n",
      "  ofeowerri: 13.85%\n",
      "\n",
      "Amala-And-Ewedu.jpeg\n",
      "  ewedu: 95.19%\n",
      "  ogbono: 4.62%\n",
      "  egusi: 4.37%\n",
      "\n",
      "image.jpg\n",
      "  akarabread: 98.43%\n",
      "  garriandgrounut: 2.23%\n",
      "  pufpuf: 2.07%\n"
     ]
    }
   ],
   "source": [
    "#Testing with multiple images\n",
    "test_path = \"../src/food_classifier/test_images\"\n",
    "\n",
    "# If directory, pick one or loop through all\n",
    "if os.path.isdir(test_path):\n",
    "    files = [f for f in os.listdir(test_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No image files found in directory: {test_path}\")\n",
    "else:\n",
    "    files = [os.path.basename(test_path)]\n",
    "    test_path = os.path.dirname(test_path)\n",
    "\n",
    "# Loop through each image file\n",
    "for filename in files:\n",
    "    img_path = os.path.join(test_path, filename)\n",
    "    with open(img_path, \"rb\") as image_data:\n",
    "        image_bytes = image_data.read()\n",
    "        results = predictor.classify_image(\n",
    "            project.id,\n",
    "            publish_iteration_name,\n",
    "            image_bytes\n",
    "        )\n",
    "\n",
    "    print(f\"\\n{filename}\")\n",
    "    for prediction in results.predictions[:3]:\n",
    "        print(f\"  {prediction.tag_name}: {prediction.probability * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc065fb2",
   "metadata": {},
   "source": [
    "## **Documentations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f08f960",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Azure Custom Vision Food Image Classifier  \n",
    "**Contributor:** *Robiu Olalere / Algebra101*  \n",
    "\n",
    "---\n",
    "\n",
    "## Overview  \n",
    "This notebook demonstrates how to build a **food image classifier** using **Azure Custom Vision** and a **Kaggle dataset of Nigerian foods**.  \n",
    "The objective was to automate dataset upload, train a multiclass classifier, and expose prediction endpoints for local inference.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset  \n",
    "- **Source:** [Nigeria Food AI Dataset (Kaggle)](https://www.kaggle.com/datasets/elinteerie/nigeria-food-ai-dataset)  \n",
    "- The dataset is stored in a **binary format**, so it must be **extracted** before Azure Custom Vision recognizes the images.  \n",
    "- There is noticeable **class imbalance**, which slightly reduced recall for underrepresented classes.  \n",
    "- Example: foods with fewer samples showed recall below 50%, while classes with more samples achieved higher precision and recall.\n",
    "\n",
    "---\n",
    "\n",
    "## Data Upload  \n",
    "A custom uploader script was implemented to handle robust dataset uploading:\n",
    "\n",
    "- Handles extraction from KaggleHub cache.  \n",
    "- Uploads images in **batches of 64** (Azure’s upload limit).  \n",
    "- Supports **automatic resume** after network interruptions using a local progress checkpoint file.  \n",
    "- Total upload time: **≈ 29 minutes 30 seconds**.  \n",
    "\n",
    "---\n",
    "\n",
    "## Model Training  \n",
    "- **Project type:** Classification (Multiclass)  \n",
    "- **Training duration:** 12 minutes 32 seconds  \n",
    "\n",
    "**Performance (Threshold = 50%)**\n",
    "| Metric | Score |\n",
    "|:--|:--|\n",
    "| Precision | 92.2% |\n",
    "| Recall | 74.7% |\n",
    "| Average Precision (AP) | 91.2% |\n",
    "\n",
    "**Observations**\n",
    "- High-sample classes → stronger precision and recall.  \n",
    "- Some smaller classes still performed well despite low image counts.\n",
    "\n",
    "---\n",
    "\n",
    "## API Keys and Environment  \n",
    "During experimentation, it was observed that:\n",
    "- If the initial API key fails or expires, a **manual override** in the code may be required even after updating the `.env` file.  \n",
    "- The guide includes steps for resetting and re-authenticating both **Training** and **Prediction** clients programmatically.  \n",
    "\n",
    "---\n",
    "\n",
    "## Prediction Endpoints  \n",
    "**Image URL Endpoint:**  \n",
    "\n",
    "\n",
    "[https://myclassifier-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/cbb3b58c-7d5e-4436-9ab3-5af77ee3f197/classify/iterations/FoodClassifierModel/url](https://myclassifier-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/cbb3b58c-7d5e-4436-9ab3-5af77ee3f197/classify/iterations/FoodClassifierModel/url)\n",
    "\n",
    "\n",
    "**Image File Endpoint:**  \n",
    "\n",
    "\n",
    "[https://myclassifier-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/cbb3b58c-7d5e-4436-9ab3-5af77ee3f197/classify/iterations/FoodClassifierModel/image](https://myclassifier-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/cbb3b58c-7d5e-4436-9ab3-5af77ee3f197/classify/iterations/FoodClassifierModel/image)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Example Inference (Python)\n",
    "\n",
    "```python\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "\n",
    "# Replace with your own values\n",
    "PREDICTION_KEY = \"<your_prediction_key>\"\n",
    "ENDPOINT = \"<your_endpoint>\"\n",
    "PROJECT_ID = \"<your_project_id>\"\n",
    "ITERATION_NAME = \"FoodClassifierModel\"\n",
    "\n",
    "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": PREDICTION_KEY})\n",
    "predictor = CustomVisionPredictionClient(ENDPOINT, credentials)\n",
    "\n",
    "with open(\"test_image.jpg\", \"rb\") as image_data:\n",
    "    results = predictor.classify_image(PROJECT_ID, ITERATION_NAME, image_data.read())\n",
    "\n",
    "for prediction in results.predictions:\n",
    "    print(f\"{prediction.tag_name}: {prediction.probability * 100:.2f}%\")\n",
    "````\n",
    "\n",
    "---\n",
    "\n",
    "## Notes and Recommendations\n",
    "\n",
    "* The class imbalance could be addressed by **oversampling** or **data augmentation** for smaller categories.\n",
    "* Future contributors can experiment with:\n",
    "\n",
    "  * **Advanced Training** mode in Azure Custom Vision\n",
    "  * **AutoML** for additional optimization\n",
    "* The notebook and documentation serve as a reproducible baseline for food image classification tasks in Azure Custom Vision.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec3c02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
